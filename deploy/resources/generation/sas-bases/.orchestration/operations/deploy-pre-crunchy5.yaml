apiVersion: orchestration.sas.com/v3beta1
kind: LifecycleOperation
metadata:
  annotations:
    sas.com/component-name: sas-crunchy5-postgres-operator
    sas.com/component-version: 1.5.14-20250307.1741371455359
  creationTimestamp: null
  labels:
    participate.lifecycle.sas.com/deploy-pre: "true"
  name: deploy-pre-crunchy5
spec:
  args:
  - name: namespace
    required: true
  - name: timeout
    required: true
  - name: manifest
    required: true
  - name: serviceAccountName
  source: "package main\n\nimport (\n  \"fmt\"\n  \"sas/orchestration/lifecycle\"\n  c \"sas/orchestration/lifecycle/cluster\"\n  m \"sas/orchestration/lifecycle/manifest\"\n  \"strconv\"\n  \"strings\"\n  \"time\"\n)\n\nfunc main() {\n  namespace := lifecycle.Arg(\"namespace\")\n  timeout := lifecycle.Arg(\"timeout\")\n  manifest := lifecycle.Arg(\"manifest\")\n  serviceAccountName := lifecycle.Arg(\"serviceAccountName\")\n  pgo_fqdn := \"postgres-operator.crunchydata.com\"\n  pgo_label := fmt.Sprintf(\"%s/control-plane=postgres-operator\", pgo_fqdn)\n  fromPostgresVersion := \"12\" //Upgrade 'from' & 'to' versions should match with PGUpgrade CR 'fromPostgresVersion:' & 'toPostgresVersion:'.\n  toPostgresVersion := \"16\"   //The automated manual script 'postgres-upgrade.sh' also has these hard-coded versions which must match with each other.\n  var permissionsNeeded bool\n  if serviceAccountName == \"\" {\n    lifecycle.Log(\"ServiceAccount does not exist. Permissions to add pod/exec to sas-deployment-operator-reconcile-permissions role is not needed.\")\n    permissionsNeeded = false\n  } else {\n    lifecycle.Log(\"ServiceAccount exists. Permissions to add pod/exec to sas-deployment-operator-reconcile-permissions role are needed.\")\n    permissionsNeeded = true\n  }\n\n  //Operations to execute a postgres 12 to 16 upgrade, the \"f_*\" comments corresponds to the corresponding bash script to upgrade postgres as well\n  //Do Postgres Version Checks and get postgrescluster list\n  postgresClusters, upgrade, err := isUpgradeNeeded(namespace, fromPostgresVersion, toPostgresVersion, pgo_fqdn, manifest)\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: getting isUpgradeNeeded %v\", err))\n  }\n  lifecycle.Log(fmt.Sprintf(\"Upgrade is of value: %t\", upgrade))\n  if upgrade == false {\n    lifecycle.Log(\"Postgres Version Upgrade is not needed!\")\n    return\n  }\n  lifecycle.Log(fmt.Sprintf(\"Postgres Version checks, proceeding with upgrade from postgres version %s -> %s\", fromPostgresVersion, toPostgresVersion))\n\n  // f_shutdown_dso\n  lifecycle.Log(\"Scaling Down Data Server Operator if exists\")\n  scaleDownDataServerOperatorIfExists(namespace, timeout)\n\n  //f_drop_replicas\n  lifecycle.Log(\"Scale Down Postgres Replicas\")\n  scaleDownPostgresReplicas(namespace, postgresClusters, pgo_fqdn, timeout)\n\n  //f_check_checksums\n  lifecycle.Log(\"Checking Checksums on Postgres\")\n  applyCheckSum(namespace, postgresClusters, pgo_fqdn, permissionsNeeded, timeout)\n\n  //f_apply_crd\n  lifecycle.Log(fmt.Sprintf(\"Applying Postgres %s CRDs\", toPostgresVersion))\n  applyCrunchyCRDs(namespace, pgo_label, manifest, timeout)\n\n  //f_apply_pgo\n  lifecycle.Log(\"Applying PostgresOperator\")\n  applyPostgresOperator(namespace, postgresClusters, pgo_fqdn, pgo_label, manifest, timeout)\n\n  //f_delete_pgupgrade_cr_annotation\n  lifecycle.Log(\"Deleteing PGUpgradeCR and Annotation if exists\")\n  deletePGupgradeCRAnnotation(namespace, postgresClusters)\n\n  //f_create_pgupgrade_cr\n  lifecycle.Log(\"Creating PostgresUpgrade CR\")\n  createPosgresUpgradeCR(namespace, manifest)\n\n  //f_shutdown_pgcluster\n  lifecycle.Log(\"Shutting down PostgresCluster\")\n  shutdownPostgresCluster(namespace, postgresClusters, pgo_fqdn)\n\n  //f_annotate_pgupgrade\n  lifecycle.Log(\"Annotate pgupgrade\")\n  annotatePostgresUpgrade(namespace, postgresClusters, pgo_fqdn)\n\n  //f_wait_pgupgrade\n  lifecycle.Log(\"Wait for postgres upgrade job\")\n  waitPostgresUpgrade(namespace, postgresClusters, pgo_fqdn, \"7200s\")\n\n  //f_check_pgupgrade_status\n  lifecycle.Log(\"Check PostgresUpgrade Status\")\n  checkPostgresUpgradeStatus(namespace, postgresClusters)\n\n  //f_start_pgcluster\n  lifecycle.Log(\"Start PostgresCluster\")\n  startPostgresCluster(namespace, postgresClusters, pgo_fqdn, manifest)\n\n  //f_check_pgversion\n  assertPostgresVersion(namespace, postgresClusters, toPostgresVersion, pgo_fqdn)\n\n  lifecycle.Log(\"Start DataServer Operator\")\n  startDataServerOperator(namespace, timeout)\n\n  err, removePermissions := executePostUpgradeTasks(namespace, permissionsNeeded, serviceAccountName, postgresClusters, pgo_fqdn)\n  if err != nil && removePermissions {\n    toggleDeploymentPermissions(namespace, false)\n    if err != nil {\n      fmt.Errorf(\"ERROR: Error removing pod/exec reconcile permissions %v\", err)\n      return\n    }\n  }\n}\n\nfunc isUpgradeNeeded(namespace string, fromPostgresVersion string, toPostgresVersion string, pgo_fqdn string, manifest string) ([]string, bool, error) {\n  var postgresClusters []string\n  postgresApiResources, err := lifecycle.Kubectl(\"api-resources\", \"--api-group\", \"postgres-operator.crunchydata.com\", \"--no-headers\")\n  lifecycle.Log(\"postgresApiResources error: %s\", postgresApiResources)\n  if err != nil {\n    return postgresClusters, false, fmt.Errorf(\"ERROR: finding postgres-operator.crunchydata.com %v\", err)\n  }\n  if !strings.Contains(postgresApiResources, \"postgresclusters\") {\n    lifecycle.Log(\"Cannot find postgresclusters crd\")\n    return postgresClusters, false, nil\n  }\n  isInternal := isInternal(namespace, manifest)\n  if !isInternal {\n    return postgresClusters, false, nil\n  }\n  resources, err := c.Resources(c.Namespace(namespace), c.Resource(\"postgrescluster\"))\n  if err != nil {\n    //error getting postgresclusters\n    panic(fmt.Sprintf(\"Failed to get postgrescluster: %v\", err))\n  }\n  for _, resource := range resources {\n    postgresclusterNameI := resource.F(\"metadata\").F(\"name\").Value()\n    postgrescluster, ok := postgresclusterNameI.(string)\n    if !ok {\n      panic(fmt.Sprintf(\"PostgresCluster didn't have a name\"))\n    }\n    postgresClusters = append(postgresClusters, postgrescluster)\n  }\n\n  if fromPostgresVersion == \"\" || toPostgresVersion == \"\" {\n    panic(fmt.Sprintf(\"ERROR: Postgres versions missing\"))\n  }\n\n  if len(postgresClusters) == 0 {\n    return postgresClusters, false, nil\n  }\n\n  clusterCount := len(postgresClusters)\n  atFromVersionCount := 0\n  atToVersionCount := 0\n\n  for _, postgrescluster := range postgresClusters {\n    postgresVersion, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"postgrescluster\", postgrescluster, \"-o\", \"jsonpath={.spec.postgresVersion}\")\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: trying to retrive postgresVersion for %s cluster: %v\", postgrescluster, err))\n    }\n    if postgresVersion == fromPostgresVersion {\n      atFromVersionCount += 1\n      lifecycle.Log(fmt.Sprintf(\"PostgresCluster %s is at version %s and needs to be upgraded\", postgrescluster, fromPostgresVersion))\n    } else if postgresVersion == toPostgresVersion {\n      atToVersionCount += 1\n      lifecycle.Log(fmt.Sprintf(\"PostgresCluster %s is already at version %s and does not upgrade\", postgrescluster, toPostgresVersion))\n    } else {\n      panic(fmt.Sprintf(\"ERROR: postgresVersion of %s cluster is an unexpected one %s\", postgrescluster, postgresVersion))\n    }\n  } // end of postgresCluster for loop\n\n  if atFromVersionCount == clusterCount {\n    return postgresClusters, true, nil\n  }\n\n  if atToVersionCount == clusterCount {\n    return postgresClusters, false, nil\n  }\n  panic(fmt.Sprintf(\"ERROR: postgrescluster versions do not align\"))\n}\n\n// Checks to see if the deployment operator\nfunc isInternal(namespace string, manifest string) bool {\n  selector := fmt.Sprintf(\"postgres-operator.crunchydata.com/control-plane=postgres-operator\")\n  resources, err := m.Resources(manifest, m.Kind(\"Deployment\"), m.LabelSelector(selector))\n  if err != nil {\n    fmt.Printf(\"Did not find manifest resources with expected label '%s': %v\", \"Indicating this is external postgres deployment, do not upgrade\", selector, err)\n    return false\n  }\n  if len(resources) != 0 {\n    fmt.Printf(\"Found postgres operator deployment in manifest, indicating that this is a internal postgres deployment, proceed with upgrade.\")\n    return true\n  } else {\n    fmt.Printf(\"Did not find manifest resources with expected label '%s'.\", \"Indicating this is external postgres deployment, do not upgrade\", selector)\n    return false\n  }\n}\n\nfunc deletePGupgradeCRAnnotation(namespace string, postgresClusters []string) {\n  lifecycle.Log(\"Deleting PGUpgrade CustomResources if exists...\")\n  //Delete all pgupgrade CRs.\n  //The command always returns the return code 0. If CR doesn't exists, it displays 'No resources found'.\n  lifecycle.Kubectl(\"--namespace\", namespace, \"delete\", \"pgupgrade\", \"--all\")\n  //Delete annotations by suffixing (-) to the annotations.\n  //The command always displays '...annotated', and alwyas returns the return code 0 regardless that the annotation exists or not.\n  lifecycle.Log(\"Deleting annotations if exist\")\n  for _, postgrescluster := range postgresClusters {\n    lifecycle.Kubectl(\"--namespace\", namespace, \"annotate\", \"postgrescluster\", postgrescluster, \"postgres-operator.crunchydata.com/allow-upgrade-\")\n  }\n}\n\nfunc assertPostgresVersion(namespace string, postgresClusters []string, expectedPostgresVersion string, pgo_fqdn string) {\n  if expectedPostgresVersion == \"\" {\n    panic(fmt.Sprintf(\"ERROR: Desired Postgres Version is not defined\"))\n  }\n  for _, postgrescluster := range postgresClusters {\n    postgresVersion, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"postgrescluster\", postgrescluster, \"-o\", \"jsonpath={.spec.postgresVersion}\")\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: checking final postgresVersion on %s cluster\", postgrescluster))\n    }\n    if postgresVersion != expectedPostgresVersion {\n      panic(fmt.Sprintf(\"ERROR: Error postgresVersion of %s cluster does not match the expected PostgresVersion %s\", postgrescluster, expectedPostgresVersion))\n    }\n  }\n}\n\nfunc getPostgreClusterList(namespace string) ([]string, error) {\n  var postgresClusters []string\n  postgresApiResources, err := lifecycle.Kubectl(\"api-resources\", \"--api-group\", \"postgres-operator.crunchydata.com\", \"--no-headers\")\n  lifecycle.Log(\"postgresApiResources error: %s\", postgresApiResources)\n  if err != nil {\n    return postgresClusters, fmt.Errorf(\"ERROR: finding postgres-operator.crunchydata.com %v\", err)\n  }\n  if !strings.Contains(postgresApiResources, \"postgresclusters\") {\n    lifecycle.Log(\"Cannot find postgresclusters crd\")\n    return postgresClusters, nil\n  }\n  resources, err := c.Resources(c.Namespace(namespace), c.Resource(\"postgrescluster\"))\n  if err != nil {\n    //error getting postgresclusters\n    panic(fmt.Sprintf(\"Failed to get postgrescluster: %v\", err))\n  }\n  for _, resource := range resources {\n    postgresclusterNameI := resource.F(\"metadata\").F(\"name\").Value()\n    postgrescluster, ok := postgresclusterNameI.(string)\n    if !ok {\n      panic(fmt.Sprintf(\"PostgresCluster didn't have a name\"))\n    }\n    postgresClusters = append(postgresClusters, postgrescluster)\n  }\n  return postgresClusters, nil\n}\n\nfunc scaleDownDataServerOperatorIfExists(namespace, timeout string) {\n  // Check if the Data Server Operator deployment exists\n  resources, err := c.Resources(c.Namespace(namespace), c.Resource(\"deployments\"), c.Name(\"sas-data-server-operator\"))\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Failed to check if Data Server Operator already deployed: %v\", err))\n  }\n\n  if len(resources) != 0 {\n    selector := \"app.kubernetes.io/name=sas-data-server-operator\"\n    // Scale down Data Server Operator so that it doesn't interfere with shutting down postgrescluster\n    _, err := lifecycle.Kubectl(\"scale\", \"deploy\", \"--namespace\", namespace, \"--replicas=0\", \"sas-data-server-operator\")\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: Failed to scale down Data Server Operator deployment: %v\", err))\n    }\n    // Wait for the Data Server Operator pod to be deleted\n    _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"wait\", \"--for\", \"delete\", \"pods\", \"--selector\", selector, \"--timeout\", timeout)\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: Failed to wait for deletion of Data Server Operator pod: %v\", err))\n    }\n  }\n}\n\nfunc scaleDownPostgresReplicas(namespace string, postgresClusters []string, pgo_fqdn string, timeout string) {\n  for _, postgrescluster := range postgresClusters {\n    fmt.Printf(\"scaleDownPostgresReplicas: postgrescluster %s\", postgrescluster)\n    selector := fmt.Sprintf(\"%s/role=replica,%s/cluster=%s\", pgo_fqdn, pgo_fqdn, postgrescluster)\n    resources, err := c.Resources(c.Namespace(namespace), c.Resource(\"postgrescluster\"), c.Name(postgrescluster))\n    if err != nil && resources != nil {\n      panic(fmt.Sprintf(\"Could not find postgrescluster cr: %v\", err))\n    }\n    _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"patch\", \"postgrescluster\", postgrescluster, \"--type\", \"json\", \"-p\", `[{\"op\": \"replace\", \"path\": \"/spec/instances/0/replicas\", \"value\": 1}]`)\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: Failed to scale down PostgresCluster: %v\", err))\n    }\n\n    _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"wait\", \"--for\", \"delete\", \"pods\", \"--selector\", selector, \"--timeout\", timeout)\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: Failed to wait for deletion of postgres pods: %v\", err))\n    }\n  }\n}\n\n// Do not panic in this function as it is necessary when called in applyCheckSum function\nfunc getChecksum(namespace string, primary_pod string) (error, string) {\n  output, err := lifecycle.Kubectl(\"--namespace\", namespace, \"exec\", primary_pod, \"-c\", \"database\", \"--\", \"psql\", \"-t\", \"-A\", \"-c\", \"show data_checksums\")\n  if err != nil {\n    return fmt.Errorf(\"ERROR: Failed to show data_checksums: %v\", err), \"\"\n  }\n  //remove whitespace/new line\n  output = strings.TrimSpace(output)\n  lifecycle.Log(fmt.Sprintf(\"Data_checksums is currently: %s \", output))\n  return nil, output\n}\n\n// Do not panic in this function as it is necessary when called in applyCheckSum function\n// false == stopped, true == running\nfunc getPostgresStatus(namespace string, primary_pod string, postgrescluster string, desiredState string) (error, string) {\n  // Check the Postgres processes\n  command := fmt.Sprintf(\"ps xf | grep %s | grep -v grep | wc -l\", postgrescluster)\n  output, err := lifecycle.Kubectl(\"--namespace\", namespace, \"exec\", primary_pod, \"-c\", \"database\", \"--\", \"/bin/bash\", \"-c\", command)\n  if err != nil {\n    return fmt.Errorf(\"ERROR: Failed to check the Postgres processes: %v\", err), \"Error\"\n  }\n  //Output comes as type string, convert to number\n  result := strings.TrimSpace(string(output))\n  count, err := strconv.Atoi(result)\n  if err != nil {\n    return fmt.Errorf(\"Error converting output to a number: %v\", err), \"Error\"\n  }\n\n  lifecycle.Log(fmt.Sprintf(\"The number of processes is: %d\\n\", count))\n  // If start case\n  //if number of processes >= 5 then return\n  //if number of processes < 5 then wait for certain amount of time and then check again\n  if desiredState == \"started\" {\n    if count >= 5 {\n      lifecycle.Log(\"Postgres process is running\")\n      return nil, \"started\"\n    } else {\n      lifecycle.Log(\"Postgres Process has not started yet\")\n      return nil, \"starting\"\n    }\n    //If stop case\n    // if number of processes == 0 then return\n    // if number of processes != 0 then wait for certain amount of time and then check again\n  } else if desiredState == \"stopped\" {\n    if count == 0 {\n      lifecycle.Log(\"Postgres process is stopped\")\n      return nil, \"stopped\"\n    } else {\n      lifecycle.Log(\"Postgres Process is still running\")\n      return nil, \"stopping\"\n    }\n  } else {\n    return fmt.Errorf(\"ERROR: Incorrect desired state, state must be started or Stopped\"), \"Error\"\n  }\n\n}\n\n// Do not panic in this function as it is necessary when called in applyCheckSum function\nfunc waitForPostgres(namespace string, primary_pod string, postgresCluster string, desiredState string) error {\n  maxWait := 180 * time.Second //Maximum wait time in seconds\n  interval := 5 * time.Second  //Interval between checks in seconds\n  totalWait := 0 * time.Second\n  fmt.Printf(\"Checking postgres process for %s with the primary pod %s\", postgresCluster, primary_pod)\n  for {\n    if totalWait > maxWait {\n      return fmt.Errorf(\"Timed out waiting for postgres process for %s with the primary pod %s. Max wait time %v\", postgresCluster, primary_pod, maxWait)\n    }\n    //Check if the PG processes exist\n    err, status := getPostgresStatus(namespace, primary_pod, postgresCluster, desiredState)\n    if err != nil {\n      return fmt.Errorf(\"ERROR: error getting the postgress process count %v\", err)\n    }\n    if status == desiredState {\n      fmt.Printf(\"Postgres process is in desired state %v after %v seconds\", desiredState, totalWait)\n      return nil\n    }\n    fmt.Printf(\"Total Wait: %s, sleeping for %s\", totalWait, interval)\n    time.Sleep(interval)\n    totalWait = totalWait + interval\n\n  }\n\n}\n\n// This is complicated function. The overall flow is to add pod/exec permissions for the Orchestration Deployment Operator Scenario.\n// We check the checksum status, which results in 3 different scenarios (\"on\"|\"off\"|unkown). The \"off\" scenario is the only scenario in which we take action.\n// After each scenario, we remove the pod/exec permissions from the service account\nfunc applyCheckSum(namespace string, postgresClusters []string, pgo_fqdn string, permissionsNeeded bool, timeout string) {\n  for _, postgrescluster := range postgresClusters {\n\n    //Get the primary pod\n    selector := fmt.Sprintf(\"%s/cluster=%s,%s/role=master\", pgo_fqdn, postgrescluster, pgo_fqdn)\n    primary_pod, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"pods\", \"--selector\", selector, \"-o\", \"jsonpath={.items[*].metadata.name}\")\n    if err != nil || primary_pod == \"0\" {\n      panic(fmt.Sprintf(\"ERROR: Failed to find primary postgres pod: %v\", err))\n    }\n\n    //Apply permissions to add permissions to exec into pods\n    //From this point on, we will not panic even if there is an error (with the exception of failing to add/remove the pod/exec permissions).\n    //This is necessary to not leave Postgres in a broken state and to remove the pod/exec permissions\n    if permissionsNeeded {\n      err := toggleDeploymentPermissions(namespace, true)\n      if err != nil {\n        panic(fmt.Errorf(\"ERROR: Error adding pod/exec reconcile permissions %v\", err))\n      }\n    }\n\n    err, status := getChecksum(namespace, primary_pod)\n    if err != nil {\n      lifecycle.Log(fmt.Sprintf(\"ERROR: getting checksum status: %v\", err))\n    }\n    lifecycle.Log(fmt.Sprintf(\"Current Checksum Status: %s\", status))\n\n    //Status is on, no need to do anything\n    if status == \"on\" {\n      lifecycle.Log(fmt.Sprintf(\"Data_checksums is %s, no further action required\", status))\n      //Remove pod/exec permissions and return\n      if permissionsNeeded {\n        err := toggleDeploymentPermissions(namespace, false)\n        if err != nil {\n          panic(fmt.Errorf(\"ERROR: Error adding pod/exec reconcile permissions %v\", err))\n        }\n      }\n\n      //Status is off, need to do a lot of stuff to enable checksum\n      //If there is an error that occurs during these operations we will flip enableChecksumSuccessful to false and at the end of this function, return error out and terminate the upgrade\n      //It is important that if an error occurs, all the steps to resume postgres functionality still runs in order to not leave postgres in a broken state.\n      //Do not return in order to remove the pod/exec priveledges in the Orchestration deploy scenario\n    } else if status == \"off\" {\n      lifecycle.Log(fmt.Sprintf(\"Updating cluster %s to enable checksum on the primary pod %s\", postgrescluster, primary_pod))\n      //Temporarily pause the cluster management of Crunchy Operator (PGO)\n      _, err := lifecycle.Kubectl(\"--namespace\", namespace, \"patch\", \"postgrescluster\", postgrescluster, \"--type\", \"merge\", \"--patch\", `{\"spec\":{\"paused\": true}}`)\n      if err != nil {\n        lifecycle.Log(fmt.Sprintf(\"ERROR: Failed to pause PGO: %v\", err))\n      }\n\n      //Temporarily pause patroni operations\n      enableChecksumSuccessful := false\n      _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"exec\", primary_pod, \"-c\", \"database\", \"--\", \"patronictl\", \"pause\")\n      if err != nil {\n        lifecycle.Log(fmt.Sprintf(\"ERROR: Failed to pause Patroni: %v\", err))\n      } else {\n        // Stop the Postgres processes\n        command := fmt.Sprintf(\"pg_ctl stop -D /pgdata/pg12 -m fast\")\n        _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"exec\", primary_pod, \"-c\", \"database\", \"--\", \"/bin/bash\", \"-c\", command)\n        if err != nil {\n          lifecycle.Log(fmt.Sprintf(\"ERROR: Failed to stop the Postgres processes: %v\", err))\n        } else {\n          lifecycle.Log(\"Waiting for Postgres to be stopped\")\n          err = waitForPostgres(namespace, primary_pod, postgrescluster, \"stopped\")\n          if err != nil {\n            lifecycle.Log(fmt.Sprintf(\"ERROR: error waiting for postgres to stop\"))\n          } else {\n            //Helpful to just give it a bit more time to shutdown\n            time.Sleep(5 * time.Second)\n            // Run pg_checksums binary\n            command = fmt.Sprintf(`logFile=\"/pgdata/pg_up_09_chksum_enable.log\"; pg_checksums --enable --pgdata /pgdata/pg12 --progress --verbose >> $logFile 2>&1; echo >> $logFile;`)\n            _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"exec\", primary_pod, \"-c\", \"database\", \"--\", \"/bin/bash\", \"-c\", command)\n            if err != nil {\n              lifecycle.Log(fmt.Sprintf(\"ERROR: Failed to enable checksum: %v\", err))\n            } else {\n              //The following commands above all ran successfully, thus indicating that the data_checksums was turned on.\n              lifecycle.Log(\"Enabling data_checksums was successful\")\n              enableChecksumSuccessful = true\n            }\n          }\n        }\n      }\n\n      // Try reversing the temp 'pause' whether there was an error or not. Do not return on error of the commands to continue reversing.\n      // Resume patroni operations. This starts the Postgres process.\n      _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"exec\", primary_pod, \"-c\", \"database\", \"--\", \"patronictl\", \"resume\")\n      if err != nil {\n        lifecycle.Log(fmt.Sprintf(\"ERROR: Failed to Resume patroni operations: %v\", err))\n      }\n      lifecycle.Log(\"Waiting for Postgres to be started\")\n      err = waitForPostgres(namespace, primary_pod, postgrescluster, \"started\")\n      if err != nil {\n        lifecycle.Log(fmt.Sprintf(\"ERROR: error occurred waiting for postgres to start\"))\n      }\n      //Helpful to just give it a bit more time to start up\n      time.Sleep(5 * time.Second)\n\n      // Check the Postgres cluster status\n      _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"exec\", primary_pod, \"-c\", \"database\", \"--\", \"patronictl\", \"list\")\n      if err != nil {\n        lifecycle.Log(fmt.Sprintf(\"ERROR: Failed to check the Postgres cluster status: %v\", err))\n      }\n\n      //Check if the PG checksum setting is \"on\"\n      err, status := getChecksum(namespace, primary_pod)\n      if err != nil {\n        lifecycle.Log(fmt.Sprintf(\"ERROR: getting checksum status: %v\", err))\n      }\n      lifecycle.Log(fmt.Sprintf(\"Resulting checksum setting is: %s\", status))\n\n      // Resume the cluster management of Crunchy Operator\n      _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"patch\", \"postgrescluster\", postgrescluster, \"--type\", \"merge\", \"--patch\", `{\"spec\":{\"paused\": false}}`)\n      if err != nil {\n        lifecycle.Log(fmt.Sprintf(\"ERROR: Failed to resume PGO: %v\", err))\n      }\n\n      //Remove permissions to exec into pods\n      if permissionsNeeded {\n        err := toggleDeploymentPermissions(namespace, false)\n        if err != nil {\n          panic(fmt.Sprintf(\"ERROR: Error removing pod/exec reconcile permissions %v\", err))\n        }\n      }\n      if enableChecksumSuccessful && status == \"on\" {\n        lifecycle.Log(fmt.Sprintf(\"Data_checksums is %s. Successfully turned on checksum\", status))\n      } else {\n        panic(fmt.Sprintf(\"ERROR: Data_checksums is %s. Failed to turn on checksum panicing and exiting the upgrade\", status))\n      }\n\n      //Uknown case, neither \"on\"or \"off\" scenario\n    } else {\n      //Remove permissions to exec into pods\n      if permissionsNeeded {\n        err := toggleDeploymentPermissions(namespace, false)\n        if err != nil {\n          panic(fmt.Sprintf(\"ERROR: Error removing pod/exec reconcile permissions %v\", err))\n        }\n      }\n        panic(fmt.Sprintf(\"ERROR: Checksum status is not 'on' nor 'off': %s. Postgres may be down. Postgres Upgrade cannot be proceeded\", status))\n    }\n  }\n}\nfunc applyCrunchyCRDs(namespace string, pgo_label string, manifest string, timeout string) {\n  lifecycle.Log(\"Applying Crunchy CRDs...\")\n  selector := fmt.Sprintf(\"sas.com/admin=cluster-api,%s\", pgo_label)\n  _, err := lifecycle.Kubectl(\"apply\", \"--selector\", selector, \"-f\", manifest, \"--server-side\", \"--force-conflicts\")\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Could not apply CrunchyCRD %v\", err))\n  }\n  // Sleep before starting to wait. It is to work around the kubectl issue (DEPENBDAT-2358)\n  time.Sleep(10 * time.Second)\n  _, err = lifecycle.Kubectl(\"wait\", \"crd\", \"--for\", \"condition=established\", \"--selector\", selector, \"--timeout\", timeout)\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Crunchy CRDs failed to be applied %v\", err))\n  }\n\n  //Check if crds are found\n  crd, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"crd\", \"--selector\", selector, \"-o\", \"jsonpath='{.items[*].metadata.name}'\")\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Could not find Crunchy CRDs %v\", err))\n  }\n  lifecycle.Log(\"Found Crunchy CRDs %s\", crd)\n}\n\nfunc applyPostgresOperator(namespace string, postgresClusters []string, pgo_fqdn string, pgo_label string, manifest string, timeout string) {\n  lifecycle.Log(\"Applying Crunchy Postgres Operator...\")\n  clusterWideSelector := fmt.Sprintf(\"sas.com/admin=cluster-wide,%s\", pgo_label)\n  namespaceSelector := fmt.Sprintf(\"sas.com/admin=namespace,%s\", pgo_label)\n  _, err := lifecycle.Kubectl(\"apply\", \"--selector\", clusterWideSelector, \"-f\", manifest)\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Failed to apply Crunchy Postgres Operator %v\", err))\n  }\n\n  _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"serviceaccount\", \"--selector\", clusterWideSelector)\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Failed get serviceaccount %v\", err))\n  }\n\n  _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"role\", \"--selector\", clusterWideSelector)\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Failed get role %v\", err))\n  }\n\n  //Creates rolebinding.rbac.authorization.k8s.io/postgres-operator\n  _, err = lifecycle.Kubectl(\"apply\", \"--selector\", fmt.Sprintf(\"sas.com/admin=cluster-local,%s\", pgo_label), \"-f\", manifest, \"--prune\")\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Failed to apply Crunchy Postgres Operator %v\", err))\n  }\n\n  _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"rolebinding\", \"--selector\", clusterWideSelector)\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Failed get rolebinding %v\", err))\n  }\n\n  // Creates deployment.apps/sas-crunchy5-postgres-operator\n  _, err = lifecycle.Kubectl(\"apply\", \"--selector\", namespaceSelector, \"-f\", manifest, \"--prune\", \"--prune-allowlist=autoscaling/v2/HorizontalPodAutoscaler\")\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Failed to apply Crunchy Postgres Operator %v\", err))\n  }\n\n  pgo_deploy, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"deploy\", \"--selector\", namespaceSelector, \"-o\", \"jsonpath={.items[*].metadata.name}\")\n  if err != nil || pgo_deploy == \"\" {\n    panic(fmt.Sprintf(\"ERROR: Failed get pgo deployment %v\", err))\n  }\n\n  lifecycle.Log(\"Found PGO Deployment %s\", pgo_deploy)\n\n  // Sleep before starting to wait for pgo rollout. It is to work around the potential kubectl wait issue\n  time.Sleep(10 * time.Second)\n\n  _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"rollout\", \"status\", fmt.Sprintf(\"deployment/%s\", pgo_deploy), \"--timeout\", \"600s\")\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Failed to get deployment rollout status %v\", err))\n  }\n\n  lifecycle.Log(\"Waiting for pgclusters to be restarted after PGO is rolled out...\")\n  maxTry := len(postgresClusters)*2 + 1\n  for i := 0; i <= maxTry; i++ {\n    fmt.Printf(\"Wait loop: %v/%v\", i, maxTry)\n    time.Sleep(10 * time.Second)\n\n    _, err := lifecycle.Kubectl(\"--namespace\", namespace, \"wait\", \"pods\", \"--for\", \"condition=ready\", \"--selector\", fmt.Sprintf(\"%s/cluster,%s/data\", pgo_fqdn, pgo_fqdn), \"--timeout\", \"600s\")\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: Error occurred checking the condition of postgrescluster restarts %v\", err))\n    }\n  }\n\n  _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"wait\", \"--for\", \"condition=ready\", \"pods\", \"--selector\", fmt.Sprintf(\"%s/cluster,%s/data\", pgo_fqdn, pgo_fqdn), \"--timeout\", \"600s\")\n  if err != nil {\n    fmt.Errorf(\"Kubectl wait for pgo pods to be ready failed\")\n  }\n\n  pgo_pod, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"pod\", \"--selector\", pgo_label, \"-o\", \"jsonpath={.items[*].metadata.name}\")\n  if err != nil || pgo_pod == \"\" {\n    panic(fmt.Sprintf(\"ERROR: Failed to get pgo pod %v\", err))\n  }\n  lifecycle.Log(\"PGO Pod is found! %s\", pgo_pod)\n}\n\nfunc createPosgresUpgradeCR(namespace string, manifest string) {\n  fmt.Printf(\"Create PGUpgrade CRs...\")\n  _, err := lifecycle.Kubectl(\"--namespace\", namespace, \"apply\", \"-f\", manifest, \"--selector\", \"sas.com/pgupgrade-cr\")\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Failed to apply PostgresUgrade CR %v\", err))\n  }\n\n  _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"pgupgrade\")\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Failed pgupgrade CR %v\", err))\n  }\n\n  //Check if pgupgrade CRs are found\n  pg_upgrade, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"pgupgrade\", \"-o\", \"jsonpath={.items[*].metadata.name}\")\n  if err != nil || pg_upgrade == \"\" {\n    panic(fmt.Sprintf(\"ERROR: Failed to get pgo pod %v\", err))\n  }\n  lifecycle.Log(\"pgupgrade found %s\", pg_upgrade)\n}\n\nfunc shutdownPostgresCluster(namespace string, postgresClusters []string, pgo_fqdn string) {\n  for _, postgrescluster := range postgresClusters {\n    selector := fmt.Sprintf(\"%s/cluster=%s,%s/data\", pgo_fqdn, postgrescluster, pgo_fqdn)\n    lifecycle.Log(\"Shutting down the cluster, %s\", postgrescluster)\n    _, err := lifecycle.Kubectl(\"--namespace\", namespace, \"patch\", \"postgrescluster\", postgrescluster, \"--type\", \"json\", \"-p\", `[{\"op\": \"replace\", \"path\": \"/spec/shutdown\", \"value\": true}]`)\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: Failed to shutdown postgrescluster: %v\", err))\n    }\n\n    _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"wait\", \"pods\", \"--for=delete\", \"--selector\", selector, \"--timeout\", \"600s\")\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: Failed to wait for postgres cluster to be shutdown %v\", err))\n    }\n\n    //Check if all PG pods are deleted. Note: If selector is used, it always returns 0.\n    pg_pods, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"pod\", \"--selector\", selector, \"-o\", \"jsonpath={.items[*].metadata.name}\")\n    if err != nil || pg_pods == \"0\" {\n      panic(fmt.Sprintf(\"ERROR: Postgres pods are left undeleted %v\", err))\n    }\n  }\n}\n\nfunc annotatePostgresUpgrade(namespace string, postgresClusters []string, pgo_fqdn string) {\n  for _, postgrescluster := range postgresClusters {\n    lifecycle.Log(\"Annotate for the upgrade of %s\", postgrescluster)\n    _, err := lifecycle.Kubectl(\"--namespace\", namespace, \"annotate\", \"postgrescluster\", postgrescluster, fmt.Sprintf(\"%s/allow-upgrade=%s-upgrade\", pgo_fqdn, postgrescluster))\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: Failed to annotate postgres upgrade %v\", err))\n    }\n  }\n}\n\nfunc waitPostgresUpgrade(namespace string, postgresClusters []string, pgo_fqdn string, timeout string) {\n  for _, postgrescluster := range postgresClusters {\n    lifecycle.Log(\"Waiting for the %s pgupgrade job to finish...\", postgrescluster)\n    selector := fmt.Sprintf(\"%s/cluster=%s,%s/pgupgrade=%s-upgrade\", pgo_fqdn, postgrescluster, pgo_fqdn, postgrescluster)\n\n    waitObjectCreated(namespace, \"job\", selector)\n    //Check if the object exists, and if not, then wait for it to be created\n    _, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"job\", \"--selector\", selector)\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: Failed to get postgres upgrade job %v\", err))\n    }\n\n    //Dump upgrade job logs\n    lifecycle.Log(\"============================get yaml output========================\")\n    lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"pgupgrade\", fmt.Sprintf(\"%s-upgrade\", postgrescluster), \"-o\", \"yaml\")\n    lifecycle.Log(\"============================describe output========================\")\n    lifecycle.Kubectl(\"--namespace\", namespace, \"describe\", \"pgupgrade\", fmt.Sprintf(\"%s-upgrade\", postgrescluster))\n\n    //Commented out code to dump the logs of the pgupgrade pods\n    //However due to permission limitations on Lifecycle Operations\n    //Lifecycle operations cannot run kubectl logs commands. Keeping this code incase we need it in the future\n    // lifecycle.Log(\"Looking for pods %s pods\", selector)\n    // resources, err := c.Resources(c.Namespace(namespace), c.Resource(\"pods\"), c.LabelSelector(selector))\n    // if err != nil {\n    // \tpanic(fmt.Sprintf(\"ERROR: Failed to get %s pods to grab upgrade logs: %v\", selector, err))\n    // }\n\n    // for _, resource := range resources {\n    // \tpodNameI := resource.F(\"metadata\").F(\"name\").Value()\n    // \tpodName, ok := podNameI.(string)\n    // \tif !ok {\n    // \t\tpanic(fmt.Sprintf(\"ERROR: %s, pod did not have a name\", selector))\n    // \t}\n    // \tlifecycle.Log(\"Printing logs for %s\", podName)\n    // \t//Print out logs of Pgupgrade log\n    // \t_, err = lifecycle.Kubectl(\"--namespace\", namespace, \"logs\", podName)\n    // \tif err != nil {\n    // \t\tpanic(fmt.Sprintf(\"ERROR: Failed to get logs of %s pod: %v\", podName, err))\n    // \t}\n    // }\n\n    //Wait for the job to be completed. Note: condition is NOT 'completed' BUT 'complete' (case insensitive)\n    //Using '--timeout' makes a job failure case to wait until timeout instead returning at the failure.\n    //But without '--timeout', the 'wait' returns 'timeout' prematurely. So, use it always.\n    _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"wait\", \"job\", \"--for\", \"condition=complete\", \"--selector\", selector, \"--timeout\", timeout)\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: Failed to wait for postgres upgrade job to complete %v\", err))\n    }\n\n    job_name, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"job\", \"--selector\", selector, \"-o\", \"jsonpath={.items[*].metadata.name}\")\n    job_status, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"job\", job_name, \"-o\", \"jsonpath={.status.conditions[?(@.type=='Complete')].status}\")\n    failed_pods, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"job\", job_name, \"-o\", \"jsonpath={.status.failed}\")\n    if job_status == \"True\" {\n      lifecycle.Log(\"job %s completed successfully\", job_status)\n    } else if failed_pods != \"\" {\n      panic(fmt.Sprintf(\"Jobe %s has failed\", job_name))\n    } else {\n      panic(fmt.Sprintf(\"Job %s is in an unknown state\", job_name))\n    }\n\n  }\n}\n\nfunc checkPostgresUpgradeStatus(namespace string, postgresClusters []string) {\n\n  for _, postgrescluster := range postgresClusters {\n    lifecycle.Log(\"Checking the PGUpgrade CustomResource status for %s-upgrade...\", postgrescluster)\n    selector := fmt.Sprintf(\"%s-upgrade\", postgrescluster)\n    status_reason, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"pgupgrade\", selector, \"-o\", \"jsonpath={.status.conditions[-1].reason}\")\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: Failed to get pgupgrade reason %v\", err))\n    }\n    lifecycle.Log(\"Status_reason: %s\", status_reason)\n    status_status, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"pgupgrade\", selector, \"-o\", \"jsonpath={.status.conditions[-1].status}\")\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: Failed to get pgupgrade status %v\", err))\n    }\n    lifecycle.Log(\"status_status: %s\", status_status)\n\n    status_type, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"pgupgrade\", selector, \"-o\", \"jsonpath={.status.conditions[-1].type}\")\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: Failed to get pgupgrade type %v\", err))\n    }\n    lifecycle.Log(\"status_type: %s\", status_type)\n    if status_reason == \"PGUpgradeSucceeded\" && status_status == \"True\" && status_type == \"Succeeded\" {\n      lifecycle.Log(\"PGUpgrade was successful\")\n    } else {\n      panic(fmt.Sprintf(\"ERROR: PGUpgrade failed. Check the log of the pgupgrade pod\"))\n    }\n  }\n}\n\nfunc startPostgresCluster(namespace string, postgresClusters []string, pgo_fqdn string, manifest string) {\n\n  lifecycle.Log(\"Applying PostgreSQL new image to the upgraded cluster...\")\n  // Sleep before starting to wait. It is to work around the kubectl issue (DEPENBDAT-2358)\n  time.Sleep(30 * time.Second)\n  //applies postgrescluster customer resources for updated postgres\n  _, err := lifecycle.Kubectl(\"apply\", \"--selector\", \"sas.com/postgrescluster-cr\", \"-f\", manifest)\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Failed to apply new postgres images on the upgraded cluster %v\", err))\n  }\n  // Sleep before starting to wait. It is to work around the kubectl issue (DEPENBDAT-2358)\n  time.Sleep(10 * time.Second)\n  //Wait for the primary pod running\n  for _, postgrescluster := range postgresClusters {\n    //PostgresCluster CR sets 'shutdown:' to false, so the cluster is started.\n    //Check if the object exists, and if not, then wait for it to be created.\n    lifecycle.Log(\"Waiting for the primary node (leader) to be running...\")\n    waitObjectCreated(namespace, \"pods\", fmt.Sprintf(\"%s/cluster=%s,%s/role=master\", pgo_fqdn, postgrescluster, pgo_fqdn))\n    _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"wait\", \"pods\", \"--for\", \"condition=ready\", \"--selector\", fmt.Sprintf(\"%s/cluster=%s,%s/role=master\", pgo_fqdn, postgrescluster, pgo_fqdn), \"--timeout\", \"300s\")\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: Failed to wait for postgres pods to come up %v\", err))\n    }\n\n    waitObjectCreated(namespace, \"pods\", fmt.Sprintf(\"%s/cluster=%s,%s/role=master\", pgo_fqdn, postgrescluster, pgo_fqdn))\n    primary_pod, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"pods\", \"--selector\", fmt.Sprintf(\"%s/cluster=%s,%s/role=master\", pgo_fqdn, postgrescluster, pgo_fqdn), \"-o\", \"jsonpath={.items[*].metadata.name}\")\n    if err != nil || primary_pod == \"0\" {\n      panic(fmt.Sprintf(\"ERROR: Primary Postgres pods are not found %v\", err))\n    }\n    lifecycle.Log(\"Displaying the cluster status for %s using the pod %s...\", postgrescluster, primary_pod)\n    lifecycle.Log(\"NOTE: Creating replicas may take time if the database size is big, so the process continues without waiting for replicas to come up.\")\n    lifecycle.Log(\"The Postgres cluster works without replicas. In order to check the status of replicas later, run: kubectl exec %s -n %s -c database -- patronictl list\", primary_pod, namespace)\n  }\n}\n\nfunc startDataServerOperator(namespace string, timeout string) {\n  lifecycle.Log(\"Start up Data Server Operator...\")\n  selector := \"app.kubernetes.io/name=sas-data-server-operator\"\n  _, err := lifecycle.Kubectl(\"scale\", \"deploy\", \"--namespace\", namespace, \"--replicas=1\", \"sas-data-server-operator\")\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Failed start data server operator %v\", err))\n  }\n\n  //Wait the object to be created first before starting to wait for the condition.\n  lifecycle.Log(\"Calling wait for object\")\n  waitObjectCreated(namespace, \"pods\", selector)\n\n  _, err = lifecycle.Kubectl(\"wait\", \"--for=condition=Ready\", \"pods\", \"--namespace\", namespace, \"--selector\", selector, \"--timeout\", timeout)\n  if err != nil {\n    panic(fmt.Sprintf(\"ERROR: Failed to wait for data-server-operator to restart %v\", err))\n  }\n\n  dso_pod, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"pods\", \"--selector\", selector, \"-o\", \"jsonpath={.items[*].metadata.name}\")\n  if err != nil || dso_pod == \"0\" {\n    panic(fmt.Sprintf(\"ERROR: Data Server Operator pod are not found %v\", err))\n  }\n}\n\nfunc waitObjectCreated(namespace string, object string, selector string) {\n\n  maxWait := 180 * time.Second //Maximum wait time in seconds\n  interval := 5 * time.Second  //Interval between checks in seconds\n  totalWait := 0 * time.Second\n\n  fmt.Printf(\"Checking the object type %s of %s\", object, selector)\n  for {\n    if totalWait > maxWait {\n      panic(fmt.Sprintf(\"Timed out waiting for the object %s of %s. s %v\", object, selector, maxWait))\n    }\n    //Check if the object exists\n    objectCreated, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", object, \"--selector\", selector, \"-o\", \"jsonpath={.items[*].metadata.name}\")\n    if err != nil {\n      panic(fmt.Sprintf(\"ERROR: Data Server Operator pod are not found %v\", err))\n    }\n    if objectCreated != \"\" {\n      fmt.Printf(\"Object %s was found after %v seconds\", objectCreated, totalWait)\n      break\n    }\n    fmt.Printf(\"Total Wait: %s, sleeping for %s\", totalWait, interval)\n    time.Sleep(interval)\n    totalWait = totalWait + interval\n\n  }\n\n}\n\n// Purpose of this wrapper function is to ensure that rbac permissions to execute the post upgrade commands are not left unchecked.\n// If a post upgrade command fails, we ensure we delete the pod/exec grant privledges from the role.\n// The check for serviceAccountName is an implicit check to see if this is a SAS Deployment Operator deployment or a SAS Orchestration Deploy deployment\n// If the serviceAccount does not exist, then it is a SAS Orchestration Deploy deployment and it is assumed that the kubeconfig that the deployment is using has the permissions to exec into pods\n// If the serviceAccountName does exist then it is asssume that this is a SAS Deployment Operator deployment and we need to add pod/exec privledges to the sas-deployment-operator-reconcile-permissions role that is used by the operator\nfunc executePostUpgradeTasks(namespace string, permissionsNeeded bool, serviceAccountName string, postgresClusters []string, pgo_fqdn string) (error, bool) {\n  if permissionsNeeded {\n    err := toggleDeploymentPermissions(namespace, true)\n    if err != nil {\n      fmt.Errorf(\"ERROR: Error adding pod/exec reconcile permissions %v\", err)\n      return err, false\n    }\n  }\n  err := postUpgradeExtensionUpgrade(namespace, postgresClusters, pgo_fqdn)\n  if err != nil {\n    return err, true\n  }\n  err = postUpgradeVacuumdbAnalyze(namespace, postgresClusters, pgo_fqdn)\n  if err != nil {\n    return err, true\n  }\n  if permissionsNeeded {\n    err = toggleDeploymentPermissions(namespace, false)\n    if err != nil {\n      fmt.Errorf(\"ERROR: Error removing pod/exec reconcile permissions %v\", err)\n      return err, false\n    }\n  }\n  return nil, false\n}\n\n// Post-upgrade task: Upgrade extensions\n// f_post_upgrade_extension_upgrade\nfunc postUpgradeExtensionUpgrade(namespace string, postgresClusters []string, pgo_fqdn string) error {\n  lifecycle.Log(\"Post-upgrade task: Upgrading extensions...\")\n  for _, postgresCluster := range postgresClusters {\n    lifecycle.Log(\"Get the primary pod of %s\", postgresCluster)\n    selector := fmt.Sprintf(\"%s/cluster=%s,%s/role=master\", pgo_fqdn, postgresCluster, pgo_fqdn)\n    primary_pod, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"pods\", \"--selector\", selector, \"-o\", \"jsonpath={.items[*].metadata.name}\")\n    if err != nil || primary_pod == \"0\" {\n      panic(fmt.Sprintf(\"ERROR: Primary Postgres pod are not found %v\", err))\n    }\n    script := fmt.Sprintf(`logFile=\"/pgdata/upgrade_extensions.log\"; echo > $logFile; echo \"Before extensions are upgraded...\" >> $logFile; psql -c '\\dx' >> $logFile; echo >> $logFile; echo \"Original script:\" >> $logFile; cat /pgdata/update_extensions.sql >> $logFile; cp /pgdata/update_extensions.sql /pgdata/drop_create_extensions.sql; sed -i '/pgaudit/c\\DROP EXTENSION \"pgaudit\";  CREATE EXTENSION \"pgaudit\";' /pgdata/drop_create_extensions.sql; echo >> $logFile; echo \"Updated script:\" >> $logFile; cat /pgdata/drop_create_extensions.sql >> $logFile; psql -f /pgdata/drop_create_extensions.sql | tee -a $logFile; echo >> $logFile; echo \"After extensions are upgraded...\" >> $logFile; echo >> $logFile; psql -c '\\dx' >> $logFile; echo \"The log file $logFile was created to show the details of the extension upgrades\";`)\n    // Run the script within the primary pod.\n    // Do not use '-it' for exec. It is not interactive.\n    // bash -c: commands;  -e: exit on error;  -u: undeclared variables are considered as an error\n    _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"exec\", primary_pod, \"-c\", \"database\", \"--\", \"/bin/bash\", \"-ceu\", script)\n    if err != nil {\n      fmt.Errorf(\"ERROR: Unable to excute extensions upgrade call exiting %v\")\n      return err\n    }\n  }\n  return nil\n}\n\n// Post-upgrade task: Vacuumdb for analyze only\n// f_post_upgrade_vacuumdb_analyze\nfunc postUpgradeVacuumdbAnalyze(namespace string, postgresClusters []string, pgo_fqdn string) error {\n  lifecycle.Log(\"Post-upgrade task: running vacuumdb with analyze-only...\")\n  for _, postgresCluster := range postgresClusters {\n    lifecycle.Log(\"Get the primary pod of %s\", postgresCluster)\n    selector := fmt.Sprintf(\"%s/cluster=%s,%s/role=master\", pgo_fqdn, postgresCluster, pgo_fqdn)\n    primary_pod, err := lifecycle.Kubectl(\"--namespace\", namespace, \"get\", \"pods\", \"--selector\", selector, \"-o\", \"jsonpath={.items[*].metadata.name}\")\n    if err != nil || primary_pod == \"0\" {\n      panic(fmt.Sprintf(\"ERROR: Primary Postgres pod are not found %v\", err))\n    }\n    _, err = lifecycle.Kubectl(\"--namespace\", namespace, \"exec\", primary_pod, \"-c\", \"database\", \"--\", \"/bin/bash\", \"-c\", \"nohup vacuumdb --all --analyze-only >/pgdata/vacuumdb-analyze-only.log 2>&1 &\")\n    if err != nil {\n      fmt.Errorf(\"ERROR: Unable to execute vacuumdb call exiting %v\")\n      return err\n    }\n  }\n  return nil\n}\n\nfunc toggleDeploymentPermissions(namespace string, add bool) error {\n  if add {\n    lifecycle.Log(\"Adding pod exec permissions to sas-deployment-operator-reconcile-permissions role\")\n    _, err := lifecycle.Kubectl(\"--namespace\", namespace, \"patch\", \"role\", \"sas-deployment-operator-reconcile-permissions\", \"--type\", \"json\", \"-p\", `[{\"op\": \"add\", \"path\": \"/rules/0/resources/-\", \"value\": \"pods/exec\"}]`)\n    if err != nil {\n      return fmt.Errorf(\"ERROR: Cannot patch sas-deployment-operator-reconcile-permissions role to allow pods/exec permissions %v\", err)\n    }\n    return nil\n  } else {\n    lifecycle.Log(\"Removing pod exec permissions to sas-deployment-operator-reconcile-permissions role\")\n    _, err := lifecycle.Kubectl(\"--namespace\", namespace, \"patch\", \"role\", \"sas-deployment-operator-reconcile-permissions\", \"--type\", \"json\", \"-p\", `[{\"op\": \"remove\", \"path\": \"/rules/0/resources/-1\"}]`)\n    if err != nil {\n      return fmt.Errorf(\"ERROR: Cannot patch sas-deployment-operator-reconcile-permissions role to remove pods/exec permissions %v\", err)\n    }\n    return nil\n  }\n\n}"
